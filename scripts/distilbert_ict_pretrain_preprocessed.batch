#!/bin/bash
#SBATCH --time=24:00:00
#SBATCH --nodes=1 --ntasks-per-node=1 --cpus-per-task=4
#SBATCH --partition=gpu --gres=gpu:1
#SBATCH --mem=40G
#SBATCH --error=../logs/distilbert-ict.%j.err
#SBATCH --out=../logs/distilbert-ict.%j.out

module purge
ml PyTorch/1.7.1-fosscuda-2019b-Python-3.7.4

cd ../src/bert
source /home/cernypro/dev/envs/huggingface_gpu/bin/activate
# echo "PYTHONPATH=$PYTHONPATH"
# echo "PATH=$PATH"
# echo "PYTHONHOME=$PYTHONHOME"
# echo "VIRTUAL_ENV=$VIRTUAL_ENV"

XDG_RUNTIME_DIR=""
HF_HOME="/data/temporary/huggingface"
export HF_HOME

TRAINPATH='/home/cernypro/dev/source/ml4logs/data/processed/train-data-HDFS1-cv1-1_Epochs-4_Seed-13_ByBlockId_MinContext-3_MaxContext-10'
EVALPATH='/home/cernypro/dev/source/ml4logs/data/processed/val-data-HDFS1-cv1-1_Epochs-1_Seed-13_ByBlockId_MinContext-3_MaxContext-10'

mkdir -p /data/temporary/train
mkdir -p /data/temporary/eval
cp -R ${TRAINPATH}/* /data/temporary/train
cp -R ${EVALPATH}/* /data/temporary/eval

python3 -u ./train_ict_preprocessed_data.py --two-tower --output-encode-dim 100 --eval-steps 5000 --save-steps 2500 --logging-steps 50 --dataset-name M_chunked_by_blocks_min3_max10 --train-dataset /data/temporary/train --eval-dataset /data/temporary/eval
