#!/bin/bash
#SBATCH --time=24:00:00
#SBATCH --nodes=1 --ntasks-per-node=1 --cpus-per-task=4
#SBATCH --partition=gpu --gres=gpu:1
#SBATCH --mem=48G
#SBATCH --error=../logs/ict.%j.err
#SBATCH --out=../logs/ict.%j.out

module purge
ml PyTorch/1.7.1-fosscuda-2019b-Python-3.7.4

cd ../src/bert
source /home/cernypro/dev/envs/huggingface_gpu/bin/activate

XDG_RUNTIME_DIR=""
HF_HOME="/data/temporary/huggingface_${SLURM_JOB_ID}"
export HF_HOME

python3 -u ./train_ict_preprocessed_data.py \
    --two-tower $TWO_TOWER \
    --encoder-type $ENCODER_TYPE \
    --bert-model $BERT_MODEL \
    --output-encode-dim $OUTPUT_ENCODE_DIM \
    --train-batch-size $TRAIN_BATCH_SIZE \
    --target-max-seq-len $TARGET_MAX_SEQ_LEN \
    --eval-steps $EVAL_STEPS \
    --save-steps $SAVE_STEPS \
    --logging-steps $LOGGING_STEPS \
    --dataset-name ${DATASET_NAME} \
    --train-dataset ${TRAIN_DATASET} \
    --eval-dataset ${EVAL_DATASET}
