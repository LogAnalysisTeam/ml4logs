{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "described-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from typing import List, Union, Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "egyptian-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_mask(padded_batch, pad_token=0):\n",
    "    return (padded_batch != pad_token).to(torch.uint8)\n",
    "\n",
    "def _pad_truncate_add_special_tokens(batch: List[List[int]], max_len, pad_token=0, start_token=101, sep_token=102):\n",
    "    sequence_lengths = torch.tensor([min(max_len-2, len(seq)) for seq in batch], dtype=torch.int64)\n",
    "    batch_max_len = sequence_lengths.max()\n",
    "    padded_batch = torch.full(size=(len(batch), batch_max_len+2), fill_value=pad_token, dtype=torch.int64)\n",
    "    padded_batch[:, 0] = start_token\n",
    "    for seq_idx, seq in enumerate(batch):\n",
    "        padded_batch[seq_idx, 1:sequence_lengths[seq_idx]+1] = torch.tensor(seq[:sequence_lengths[seq_idx]], dtype=torch.int64)\n",
    "        padded_batch[seq_idx, sequence_lengths[seq_idx]+1] = sep_token\n",
    "    mask = _make_mask_torch(padded_batch)\n",
    "    return padded_batch, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "atomic-boxing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[101,  10,  20,  30,  40,  50, 102],\n",
       "         [101,  60,  70,  80, 102,   0,   0],\n",
       "         [101,  90,  91,  92,  94, 102,   0]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = [[10,20,30,40,50], [60, 70, 80], [90, 91, 92, 94]]\n",
    "\n",
    "_pad_truncate_add_special_tokens(batch, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "working-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForPreprocessedICT:\n",
    "    target_max_seq:int = 512\n",
    "    context_max_seq:int = 512\n",
    "    start_token:int = 101 # [CLS]\n",
    "    sep_token:int = 102 # [SEP]\n",
    "    pad_token:int = 0\n",
    "        \n",
    "    def _pad_truncate_add_special_tokens(self, batch: List[List[int]], max_len):\n",
    "        return _pad_truncate_add_special_tokens(batch, max_len=max_len, pad_token=self.pad_token, start_token=self.start_token, sep_token=self.sep_token)\n",
    "             \n",
    "    def __call__(self, contexts: List[Dict[str, List[int]]]):\n",
    "        if isinstance(contexts[0], dict):\n",
    "            target_sentences = [context_dict['target'] for context_dict in contexts]\n",
    "            flattened_contexts = [context_dict['flat_context'] for context_dict in contexts]\n",
    "        correct_class = torch.arange(len(target_sentences), dtype=torch.int64)\n",
    "        padded_target_batch, padded_target_mask = self._pad_truncate_add_special_tokens(target_sentences, self.target_max_seq)\n",
    "        padded_context_batch, padded_context_mask = self._pad_truncate_add_special_tokens(flattened_contexts, self.context_max_seq)\n",
    "        return {'target': padded_target_batch,\n",
    "                'target_mask': padded_target_mask,\n",
    "                'context': padded_context_batch,\n",
    "                'context_mask': padded_context_mask,\n",
    "                'correct_class': correct_class}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-criterion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
