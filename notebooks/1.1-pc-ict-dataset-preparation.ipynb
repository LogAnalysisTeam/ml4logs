{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "leading-plain",
   "metadata": {},
   "source": [
    "# TODO: Needs massive cleanup, contains random experiments with code and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "global-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizerFast, AutoModel, Trainer, TrainingArguments\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Union, Dict\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "athletic-affair",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-f7d20bad4b8d075b\n",
      "Reusing dataset text (/home/cernypro/.cache/huggingface/datasets/text/default-f7d20bad4b8d075b/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691)\n"
     ]
    }
   ],
   "source": [
    "hdfs1_dataset = load_dataset('text', data_files='../data/raw/HDFS1/HDFS.log', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "retired-voice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/cernypro/.cache/huggingface/datasets/text/default-f7d20bad4b8d075b/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691/cache-3f531662155381a4.arrow\n"
     ]
    }
   ],
   "source": [
    "def remove_timestamp(example):\n",
    "    # need to find third occurence of a space and slice the string after it\n",
    "    # using a very non robust silly solution\n",
    "    s = example['text']\n",
    "    example['text'] = s[s.find(' ', s.find(' ', s.find(' ')+1)+1)+1:]\n",
    "    return example\n",
    "\n",
    "cleaned_dataset = hdfs1_dataset.map(remove_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elect-violence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11175629"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secondary-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"distilbert-base-cased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "twelve-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_cleaned_dataset = cleaned_dataset.select(range(200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "interracial-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dontpad_dataset(examples, tokenizer):\n",
    "    return tokenizer(examples['text'], truncation=True, return_special_tokens_mask=True)\n",
    "# tokenized_unpadded_dataset = cleaned_dataset.map(tokenize_dontpad_dataset, fn_kwargs={'tokenizer': tokenizer}, batched=True, batch_size=1000, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "celtic-straight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d86bd7c17c4b299cd290ba0cb5d41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize_no_special_tokens(examples, tokenizer):\n",
    "    return {'tokens': tokenizer(examples['text'], add_special_tokens=False, truncation=True, return_attention_mask=False)['input_ids']}\n",
    "small_tokenized = small_cleaned_dataset.map(tokenize_no_special_tokens, fn_kwargs={'tokenizer': tokenizer}, batched=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "uniform-europe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chunkify(examples):\n",
    "    return {\"chunk\": [examples['tokens']]}\n",
    "chunked = small_tokenized.map(chunkify, batched=True, batch_size=10, drop_last_batch=True, remove_columns=small_tokenized.column_names, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "compressed-columbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chunk'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abstract-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForInverseClozeTaskOrig:\n",
    "    \"\"\"\n",
    "    Data Collator to be used with datasets containing contexts (List of senteces, where sentence is a list of tokens, e.g a context is a List of Lists of ints)\n",
    "    It randomly selects a sentence from each context to serve as a target, and flattens the contexts (with the target sentence randomly removed) into a single sentence to serve as a flat context\n",
    "    If using huggingface datasets, expects a column named 'chunk'\n",
    "    NOTE: This collator is quite slow, if the dataset is really large, consider pre-collating it in advance and saving it, so that the collator can then be as simple as possible\n",
    "        (example of how slow it is, when resuming almost finished training on a dataset of 800k contexts (each containing 10 lines, eg 8M lines in total)\n",
    "        using batches of size 64, resuming training took over 5 hours on 4 cores, because all the intermediate batches were created by the dataloader and collated by this collater\n",
    "        until the Trainer (huggingface) reached the saved step in the checkpoint)\n",
    "    \"\"\"\n",
    "    remove_target_from_context_probability: float = 0.9\n",
    "    target_max_seq:int = 512\n",
    "    context_max_seq:int = 512\n",
    "    start_token:int = 101 # [CLS]\n",
    "    sep_token:int = 102 # [SEP]\n",
    "    pad_token:int = 0\n",
    "        \n",
    "    def _make_mask(self, padded_batch):\n",
    "        return (padded_batch != self.pad_token).astype(np.uint8)\n",
    "        \n",
    "    def _pad_truncate_add_special_tokens(self, batch: List[List[int]], max_len): \n",
    "        sequence_lengths = np.array([min(max_len-2, len(seq)) for seq in batch])\n",
    "        batch_max_len = sequence_lengths.max()\n",
    "        padded_batch = np.full(shape=(len(batch), batch_max_len+2), fill_value=self.pad_token, dtype=np.int64)\n",
    "        padded_batch[:, 0] = self.start_token\n",
    "        for seq_idx, seq in enumerate(batch):\n",
    "            padded_batch[seq_idx, 1:sequence_lengths[seq_idx]+1] = seq[:sequence_lengths[seq_idx]]\n",
    "            padded_batch[seq_idx, sequence_lengths[seq_idx]+1] = self.sep_token\n",
    "        mask = self._make_mask(padded_batch)\n",
    "        return torch.from_numpy(padded_batch), torch.from_numpy(mask)\n",
    "    \n",
    "    def _create_target_and_flat_contexts_from_contexts(self, contexts: List[List[List[int]]]):\n",
    "        # TODO: add sep_token between each sentence when flattening context?\n",
    "        target_sentence_idxs = [torch.randint(low=0, high=len(context), size=(1,)).item() for context in contexts]\n",
    "        remove_target = [torch.rand(size=(1,)).item() < self.remove_target_from_context_probability for _ in target_sentence_idxs]\n",
    "        target_sentences = [context[i] for (i, context) in zip(target_sentence_idxs, contexts)]\n",
    "        processed_contexts = [context[:target_idx] + context[target_idx + remove:] for (target_idx, remove, context) in zip(target_sentence_idxs, remove_target, contexts)]\n",
    "        flattened_contexts = [[token for sentence in context for token in sentence] for context in processed_contexts]\n",
    "        return target_sentences, flattened_contexts\n",
    "             \n",
    "    def __call__(self, contexts: List[Union[List[List[int]], Dict[str, List[List[int]]]]]):\n",
    "        if isinstance(contexts[0], dict):\n",
    "            contexts = [context_dict['chunk'] for context_dict in contexts]\n",
    "        target_sentences, flattened_contexts = self._create_target_and_flat_contexts_from_contexts(contexts)\n",
    "        correct_class = torch.tensor(list(range(len(target_sentences))), dtype=torch.int64)\n",
    "        padded_target_batch, padded_target_mask = self._pad_truncate_add_special_tokens(target_sentences, self.target_max_seq)\n",
    "        padded_context_batch, padded_context_mask = self._pad_truncate_add_special_tokens(flattened_contexts, self.context_max_seq)\n",
    "        return {'target': padded_target_batch,\n",
    "                'target_mask': padded_target_mask,\n",
    "                'context': padded_context_batch,\n",
    "                'context_mask': padded_context_mask,\n",
    "                'correct_class': correct_class}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "spoken-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForInverseClozeTask:\n",
    "    \"\"\"\n",
    "    Data Collator to be used with datasets containing contexts (List of senteces, where sentence is a list of tokens, e.g a context is a List of Lists of ints)\n",
    "    It randomly selects a sentence from each context to serve as a target, and flattens the contexts (with the target sentence randomly removed) into a single sentence to serve as a flat context\n",
    "    If using huggingface datasets, expects a column named 'chunk'\n",
    "    NOTE: This collator is quite slow, if the dataset is really large, consider pre-collating it in advance and saving it, so that the collator can then be as simple as possible\n",
    "        (example of how slow it is, when resuming almost finished training on a dataset of 800k contexts (each containing 10 lines, eg 8M lines in total)\n",
    "        using batches of size 64, resuming training took over 5 hours on 4 cores, because all the intermediate batches were created by the dataloader and collated by this collater\n",
    "        until the Trainer (huggingface) reached the saved step in the checkpoint)\n",
    "    \"\"\"\n",
    "    remove_target_from_context_probability: float = 0.9\n",
    "    target_max_seq:int = 512\n",
    "    context_max_seq:int = 512\n",
    "    start_token:int = 101 # [CLS]\n",
    "    sep_token:int = 102 # [SEP]\n",
    "    pad_token:int = 0\n",
    "    all_contexts_same_length: bool = False\n",
    "        \n",
    "    def _make_mask(self, padded_batch):\n",
    "        return (padded_batch != self.pad_token).astype(np.uint8)\n",
    "        \n",
    "    def _pad_truncate_add_special_tokens(self, batch: List[List[int]], max_len): \n",
    "        sequence_lengths = np.array([min(max_len-2, len(seq)) for seq in batch])\n",
    "        batch_max_len = sequence_lengths.max()\n",
    "        padded_batch = np.full(shape=(len(batch), batch_max_len+2), fill_value=self.pad_token, dtype=np.int64)\n",
    "        padded_batch[:, 0] = self.start_token\n",
    "        for seq_idx, seq in enumerate(batch):\n",
    "            padded_batch[seq_idx, 1:sequence_lengths[seq_idx]+1] = seq[:sequence_lengths[seq_idx]]\n",
    "            padded_batch[seq_idx, sequence_lengths[seq_idx]+1] = self.sep_token\n",
    "        mask = self._make_mask(padded_batch)\n",
    "        return torch.from_numpy(padded_batch), torch.from_numpy(mask)\n",
    "    \n",
    "    def _get_target_sentence_idxs(self, contexts):\n",
    "        if self.all_contexts_same_length:\n",
    "            all_contexts_len = len(contexts[0])\n",
    "            return torch.randint(low=0, high=all_contexts_len, size=(len(contexts),))\n",
    "        else:\n",
    "            return [torch.randint(low=0, high=len(context), size=(1,)).item() for context in contexts]\n",
    "    \n",
    "    def _create_target_and_flat_contexts_from_contexts(self, contexts: List[List[List[int]]]):\n",
    "        # TODO: add sep_token between each sentence when flattening context?\n",
    "        target_sentence_idxs = self._get_target_sentence_idxs(contexts)\n",
    "        remove_target = torch.bernoulli(torch.full(size=(len(target_sentence_idxs),), fill_value=self.remove_target_from_context_probability)).to(torch.bool)\n",
    "        target_sentences = [context[i] for (i, context) in zip(target_sentence_idxs, contexts)]\n",
    "        processed_contexts = [context[:target_idx] + context[target_idx + remove:] for (target_idx, remove, context) in zip(target_sentence_idxs, remove_target, contexts)]\n",
    "        flattened_contexts = [[token for sentence in context for token in sentence] for context in processed_contexts]\n",
    "        return target_sentences, flattened_contexts\n",
    "             \n",
    "    def __call__(self, contexts: List[Union[List[List[int]], Dict[str, List[List[int]]]]]):\n",
    "        if isinstance(contexts[0], dict):\n",
    "            contexts = [context_dict['chunk'] for context_dict in contexts]\n",
    "        target_sentences, flattened_contexts = self._create_target_and_flat_contexts_from_contexts(contexts)\n",
    "        correct_class = torch.arange(len(target_sentences), dtype=torch.int64)\n",
    "        padded_target_batch, padded_target_mask = self._pad_truncate_add_special_tokens(target_sentences, self.target_max_seq)\n",
    "        padded_context_batch, padded_context_mask = self._pad_truncate_add_special_tokens(flattened_contexts, self.context_max_seq)\n",
    "        return {'target': padded_target_batch,\n",
    "                'target_mask': padded_target_mask,\n",
    "                'context': padded_context_batch,\n",
    "                'context_mask': padded_context_mask,\n",
    "                'correct_class': correct_class}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "adjacent-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43)\n",
    "new_col = DataCollatorForInverseClozeTask(all_contexts_same_length=True)\n",
    "old_col = DataCollatorForInverseClozeTaskOrig()\n",
    "new_dataloader = DataLoader(chunked, batch_size=16, collate_fn=new_col)\n",
    "old_dataloader = DataLoader(chunked, batch_size=16, collate_fn=old_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "first-suspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 s ± 52 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in new_dataloader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "respiratory-imperial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcd2939c150>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "defensive-object",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8 s ± 77.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in old_dataloader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "surprising-diameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MainProcess(MainProcess, started)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/cernypro/.cache/huggingface/datasets/text/default-f7d20bad4b8d075b/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691/cache-d994e89e065a9913.arrow\n",
      "Loading cached processed dataset at /home/cernypro/.cache/huggingface/datasets/text/default-f7d20bad4b8d075b/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691/cache-01988c2bed2b0797.arrow\n",
      "Loading cached processed dataset at /home/cernypro/.cache/huggingface/datasets/text/default-f7d20bad4b8d075b/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691/cache-0ebb302ab7390d01.arrow\n",
      "Loading cached processed dataset at /home/cernypro/.cache/huggingface/datasets/text/default-f7d20bad4b8d075b/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691/cache-d5cfbbb7e2fa38de.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chunk'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identity_printer(examples):\n",
    "    print(multiprocessing.current_process())\n",
    "    return examples\n",
    "\n",
    "chunked.map(identity_printer, num_proc=4, batched=True, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "finnish-disability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 5, 7, 5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "torch.randint(low=0, high=10, size=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "shaped-stations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "[int(torch.rand(size=(1,)).item() < 0.9) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "finnish-knock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "torch.bernoulli(torch.full((5,), 0.9)).to(torch.bool)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deluxe-browse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-passport",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "concrete-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClsEncoderTower(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model_name_or_path, output_encode_dimension=512):\n",
    "        super(ClsEncoderTower, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model_name_or_path)\n",
    "        self.linear = torch.nn.Linear(self.bert.config.dim, output_encode_dimension) # self.bert.config.dim most likely 768\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_token_embedding = bert_output[0][:, 0]\n",
    "        cls_encoding = self.linear(cls_token_embedding)\n",
    "        return cls_encoding\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "seasonal-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneTowerICT(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model_name_or_path, output_encode_dimension=512):\n",
    "        super(OneTowerICT, self).__init__()\n",
    "        self.tower = ClsEncoderTower(pretrained_model_name_or_path, output_encode_dimension)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    def forward(self, target, target_mask, context, context_mask, correct_class):\n",
    "        target_cls_encode = self.tower(input_ids=target, attention_mask=target_mask)\n",
    "        context_cls_encode = self.tower(input_ids=context, attention_mask=context_mask)\n",
    "        \n",
    "        logits = torch.matmul(target_cls_encode, context_cls_encode.transpose(-2, -1))\n",
    "        loss = self.loss_fn(logits, correct_class)\n",
    "        return loss, target_cls_encode, context_cls_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "alive-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerICT(torch.nn.Module):\n",
    "    def __init__(self, target_tower_pretrained_model_name_or_path, context_tower_pretrained_model_name_or_path=None, output_encode_dimension=512):\n",
    "        super(TwoTowerICT, self).__init__()\n",
    "        assert target_tower_pretrained_model_name_or_path is not None, \"Target tower pretrained model must me specified!\"\n",
    "        if context_tower_pretrained_model_name_or_path is None:\n",
    "            context_tower_pretrained_model_name_or_path = target_tower_pretrained_model_name_or_path\n",
    "        self.target_encoder = ClsEncoderTower(target_tower_pretrained_model_name_or_path, output_encode_dimension)\n",
    "        self.context_encoder = ClsEncoderTower(context_tower_pretrained_model_name_or_path, output_encode_dimension)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, target, target_mask, context, context_mask, correct_class):\n",
    "        target_cls_encode = self.target_encoder(input_ids=target, attention_mask=target_mask)\n",
    "        context_cls_encode = self.context_encoder(input_ids=context, attention_mask=context_mask)\n",
    "        \n",
    "        logits = torch.matmul(target_cls_encode, context_cls_encode.transpose(-2, -1))\n",
    "        loss = self.loss_fn(logits, correct_class)\n",
    "        return loss, target_cls_encode, context_cls_encode\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "approved-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoTowerICT(pretrained_model_name)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "treated-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/cernypro/.cache/huggingface/datasets/text/default-f7d20bad4b8d075b/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691/cache-5e8ebae16cf9f389.arrow and /home/cernypro/.cache/huggingface/datasets/text/default-f7d20bad4b8d075b/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691/cache-42be9c3ea68c8082.arrow\n"
     ]
    }
   ],
   "source": [
    "SEED=0\n",
    "RUN_NAME=\"ICT DEBUG - Two Towers 1\"\n",
    "train_test_dataset = chunked.train_test_split(test_size=256, shuffle=True, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "supreme-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForInverseClozeTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "excess-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=f\"../models/{RUN_NAME.replace(' ', '_')}\",\n",
    "                                      num_train_epochs=5,\n",
    "                                      per_device_eval_batch_size=64, \n",
    "                                      per_device_train_batch_size=64,\n",
    "                                      warmup_steps=10,                # number of warmup steps for learning rate scheduler\n",
    "                                      weight_decay=0.01,               # strength of weight decay\n",
    "                                      logging_dir='../logs',            # directory for storing logs\n",
    "                                      logging_steps=10,\n",
    "                                      logging_first_step=True,\n",
    "                                      eval_steps=20,\n",
    "                                      evaluation_strategy='steps',\n",
    "                                      prediction_loss_only=True,\n",
    "                                      save_steps=100,\n",
    "                                      save_total_limit=15,\n",
    "                                      label_names=['target', 'context'],\n",
    "                                      seed=SEED,\n",
    "                                      run_name=RUN_NAME,\n",
    "                                      remove_unused_columns=False)\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                      args=training_args,\n",
    "                      data_collator=data_collator,\n",
    "                      train_dataset=train_test_dataset['train'],\n",
    "                      eval_dataset=train_test_dataset['test']\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "overall-penalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb6921da150>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "minimal-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprokopcerny\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.21 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.19<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ICT DEBUG - Two Towers 1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/prokopcerny/huggingface\" target=\"_blank\">https://wandb.ai/prokopcerny/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/prokopcerny/huggingface/runs/2ny09mmg\" target=\"_blank\">https://wandb.ai/prokopcerny/huggingface/runs/2ny09mmg</a><br/>\n",
       "                Run data is saved locally in <code>/home/cernypro/dev/source/ml4logs/notebooks/wandb/run-20210304_125520-2ny09mmg</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 02:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.525900</td>\n",
       "      <td>3.474082</td>\n",
       "      <td>1.434300</td>\n",
       "      <td>178.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.365100</td>\n",
       "      <td>3.346828</td>\n",
       "      <td>1.448000</td>\n",
       "      <td>176.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.163100</td>\n",
       "      <td>3.354304</td>\n",
       "      <td>1.451100</td>\n",
       "      <td>176.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.346800</td>\n",
       "      <td>3.367447</td>\n",
       "      <td>1.463600</td>\n",
       "      <td>174.906000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.290700</td>\n",
       "      <td>3.209431</td>\n",
       "      <td>1.462000</td>\n",
       "      <td>175.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.101400</td>\n",
       "      <td>3.205889</td>\n",
       "      <td>1.468300</td>\n",
       "      <td>174.349000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.123900</td>\n",
       "      <td>3.287006</td>\n",
       "      <td>1.476700</td>\n",
       "      <td>173.360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=140, training_loss=3.3440962553024294, metrics={'train_runtime': 177.2968, 'train_samples_per_second': 0.79, 'total_flos': 0, 'epoch': 5.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "handy-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "trying-faculty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 0 < 246; dropping {'eval/loss': 4.083710193634033, 'eval/runtime': 7.9367, 'eval/samples_per_second': 193.783}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.083710193634033,\n",
       " 'eval_runtime': 7.9367,\n",
       " 'eval_samples_per_second': 193.783}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(train_test_dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "protecting-consciousness",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/cernypro/.cache/huggingface/datasets/text/default-3571b23bb2152210/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691/cache-5b3337e81c3dc2cb.arrow\n"
     ]
    }
   ],
   "source": [
    "def get_lenghts(example):\n",
    "    return {'length': len(example['input_ids'])}\n",
    "lenghts = tokenized_unpadded_dataset.map(get_lenghts, remove_columns=tokenized_unpadded_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "nonprofit-victoria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.6453264509765"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(lenghts['length'])\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "upper-format",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(lenghts['length'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
